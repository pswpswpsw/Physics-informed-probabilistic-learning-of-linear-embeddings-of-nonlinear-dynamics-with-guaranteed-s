#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Evaluate model performance in a posteriori

three steps

1. mapping state IC into feature space IC
2. evolving feature space IC linearly using np.linalg.expm
3. use either DL nonlinear reconstruction or simply linear Koopman modes for EDMD, KDMD.

.. note::
    we do not use any recursive interaction, simply because transforming back and tranforming into the phi and x space will cause some accumulation error

"""

import sys
sys.dont_write_bytecode = True
sys.path.insert(0,'..')

import numpy as np

from lib.lib_model_interface import *
from scipy.linalg import expm
from MODEL_SRC.lib.utilities import *
from scipy.integrate import ode
from scipy.sparse import kronsum


class ClassApoBayesEval(object):
    """Class for aposteriori Bayesian evaluation on the DL model for Koopman.

    Args:

        model (:obj:`class`):  the model class from ``lib.libm_model_interface`` .

        model_name (:obj:`str`): the name for the trained model

        case_name (:obj:`str`): problem for the case.

        mode (:obj:`str`): denote the ADVI mode being used in the model.

    Attributes:

        model (:obj:`class`): the class for the model to be used.

        model_name (:obj:`str`): the name for the trained model.

        case_name (:obj:`str`): problem for the case.

        mode (:obj:`str`): denote the ADVI mode being used in the model.

        LRAN_T (:obj:`int`): the time delay ``T`` considered, indicating whether the model is ``recurrent`` or ``differential`` as ``1`` or ``larger than 1``.

        save_dir (:obj:`str`): the path for the evaluation results to be saved. We will use the folder name ``EXAMPLES``

        K (:obj:`numpy.ndarray`): a numpy array representing the realization of K matrix.

        lambda_lin (:obj:`numpy.ndarray`): a numpy array of the realizations of the linear dynamics noises.

        noise_rec (:obj:`numpy.ndarray`): a numpy array of the realizations of the reconstruction dynamics noises.

    """

    def __init__(self, model, model_name, case_name, mode):

        self.model = model
        self.model_name = model_name
        self.case_name = case_name
        self.mode = mode  # not used for now.
        self.LRAN_T = self.model.LRAN_T
        self.save_dir = '../eval/' + case_name + '/' +  model_name + '/'
        mkdir(self.save_dir)


    def compute_analytic_exp_matrix_integration(self, A,T):
        """solve the x for :math:`Ax = e^{AT} - I`.

        Args:

            A (:obj:`numpy.ndarray`): ``A`` matrix

            T (:obj:`float`): time window.

        Returns:

            :obj:`numpy.ndarray` : returned solution :math:`x`.

        """
        return np.linalg.lstsq(A, expm(A*T) - np.eye(A.shape[0]))[0]


    def compute_exp_matrix_integration(self, A, T, nbins=1000):
        """compute exponential matrix integration using ``np.trapz`` function.

        Args:
            A (:obj:`numpy.ndarray`): ``A`` matrix

            T (:obj:`float`): time window.

            nbins (:obj:`int`): number of bins for integration.

        Returns:
            :obj:`numpy.ndarray` : integration result.
        """

        f = lambda x: expm(A*x)
        xv = np.linspace(0, T, nbins)
        result = np.apply_along_axis(f, 0, xv.reshape(1, -1))
        return np.trapz(result, xv)


    def save_koopman_eigen(self, phase_space_range):
        """Evaluate & Save the Koopman eigenfunctions plot for 2D system.

        Eigenfunctions are saved as ``koopman_eigenfunctions.npz``
        The plot is generated by sampling in each dimension 100 points.

        Args:
            phase_space_range (:obj:`numpy.ndarray`): the range of phase space to be plotted.

        """
        koopmanOp_learn_realization = self.model.get_K()

        numKoopmanModes = self.model.encoder_layer_structure[-1]

        D_real_list = []
        D_imag_list = []
        R_list = []
        for i in xrange(self.model.n_mc_samples):
            kmatrix = koopmanOp_learn_realization[i]
            [D, R] = LA.eig(kmatrix)
            D_real = np.real(D)
            D_imag = np.imag(D)
            D_real_list.append(D_real)
            D_imag_list.append(D_imag)
            R_list.append(R)

        # distribute sampling point in physical space
        x1_min, x1_max = phase_space_range[0]
        x2_min, x2_max = phase_space_range[1]

        ndraw = 100
        ndrawj = ndraw * 1j
        x1_, x2_ = np.mgrid[x1_min:x1_max:ndrawj, x2_min:x2_max:ndrawj]

        sample_x = x1_.reshape(-1, 1)
        sample_xdot = x2_.reshape(-1, 1)

        # transform x_sample into normalized space
        # sample_x    = self.scaler_x(sample_x)
        # sample_xdot = self.scaler_x(sample_xdot)

        x_sample = np.hstack((sample_x, sample_xdot))  # make it (?,2) size

        assert x_sample.shape == (ndraw ** 2, 2), "sampling shape is wrong, check visualizing eigenfunction!"

        phi_array = self.model.computePhi(x_sample)

        # SAVE
        np.savez(self.save_dir + 'koopman_eigenfunctions.npz',
                 numKoopmanModes=numKoopmanModes,
                 R=R_list,
                 phi_array=phi_array,
                 ndraw=ndraw,
                 D_real=D_real_list,
                 D_imag=D_imag_list,
                 x1_=x1_,
                 x2_=x2_
                 )



    def predict(self, tspan, ic):
        """Given initial condition as ``ic``, predicting the trajectory given ``tspan`` as time.

        We direct evaluate time that is far away, not using recursive for each delta t since it is linear system.

        Args:
            tspan (:obj:`numpy.ndarray`): time array

            ic (:obj:`numpy.ndarray`): initial condition :math:`x_0 = x(t=0)`.

        Returns:

            :obj:`numpy.ndarray` : ensemble of trajectory from Monte Carlo sampling, representing a distribution of posteriori.

        """

        # let's share the same IC

        state = ic

        # read in (1,M) state -> to generate (Q,K) Phi_0, but evaluate at many different states

        # duffing: [[0.00673038, 0.03789839, 0.0423713 ]]

        init_phi_state_mc_array = self.model.computePhi(state) # x -> phi

        # get Q realization of K

        self.K = self.model.get_K()

        # get linear lambda

        self.lambda_lin = self.model.get_lambda_lin()

        # get reconstruction noise

        self.noise_rec = self.model.get_noise_rec()

        RANDOM_SAMPLE = np.random.normal(size=(self.model.n_mc_samples, tspan.size,
                                               self.model.n_mc_diff_samples, self.K[0].shape[0]))

        state_total_mc_list = []
        if self.LRAN_T == 1:

            # diff form
            # for each phi state in Q realization, let's evolve the dynamics

            for i in xrange(self.model.n_mc_samples):

                # LAMBDA, P = np.linalg.eig(self.K[i])
                # PINV = np.linalg.inv(P)
                # LAMBDA = np.diag(LAMBDA)

                Q = np.linalg.inv(kronsum(self.K[i].astype('float64'), self.K[i].astype('float64')).toarray())

                # Q = 0.5*np.matmul(np.matmul(P, np.diag(self.lambda_lin[i])), -np.linalg.inv(LAMBDA))

                # for each sample
                print 'monte carlo run index = ', i, ': ', self.model.n_mc_samples # *self.model.n_mc_diff_samples

                state_list = [[state]*self.model.n_mc_diff_samples]

                for index_time in xrange(1, tspan.size):

                    delta_time = tspan[index_time] - tspan[0]

                    # linearly evolving phi to future - for i-th realization
                    # convert to double precision
                    time_evolution_with_K = delta_time * self.K[i]
                    time_evolution_with_K = time_evolution_with_K.astype('float64')
                    phi_state_at_t_mc_array = np.matmul(init_phi_state_mc_array[i].astype('float64'), expm(time_evolution_with_K))

                    # phi with noise
                    Q_true = -1.0 * np.matmul(Q.astype('float64'), np.eye(self.K[i].shape[0]**2) - expm( kronsum(self.K[i].astype('float64'), self.K[i].astype('float64')) * delta_time) )
                    Q_true = np.matmul(Q_true, np.diag(self.lambda_lin[i].astype('float64')).reshape(-1,1, order='F'))
                    Q_true = Q_true.reshape(self.K[i].shape[0],-1, order='F')

                    try:
                        L = np.linalg.cholesky(Q_true)
                    except:
                        print 'L is not positive definite...'
                        print('Q_true = ', Q_true)
                        print("")
                        print('K = ', self.K[i])
                        print('K = ', np.linalg.eig(self.K[i])[0])

                        print('lin = ', self.lambda_lin[i])
                        print('')
                        print(np.linalg.eig(Q_true)[0])
                        L = np.zeros(self.K[i].shape)

                    # the noise is involved via MOU process.
                    # Q_true = np.matmul(np.matmul(Q, np.eye(LAMBDA.shape[0]) - expm(2*LAMBDA*delta_time)), PINV)

                    ## need to modify a bit to make sure the round off error is removed...
                    # Q_true_real = np.real(Q_true)
                    # Q_true_symm = 0.5*(Q_true + np.conj(Q_true))

                    # try:
                    #    L = np.linalg.cholesky(Q_true_symm) # it is important to make it real..

                    #except:
                    #    print np.linalg.eigh(L)
                    #    L = np.zeros(LAMBDA.shape)

                    state_for_current_time_list = []

                    for i_mc_diff in xrange(self.model.n_mc_diff_samples):

                        NOISE_MOU = np.matmul(RANDOM_SAMPLE[i, index_time-1, i_mc_diff,:].reshape(1,-1), L).astype('float64')

                        phi_state_at_t_mc_array_noise_mou = phi_state_at_t_mc_array + NOISE_MOU # np.matmul(self.noise_lin[i], integrate_exp_tK)

                        # reconstruct x from phi state at feature
                        state_future_mc_array_noise_mou = self.model.reconstruct_with_i_realization(phi=phi_state_at_t_mc_array_noise_mou, i=i)

                        # here we will introduce reconstriction error
                        # add reconstruction noise -> it is like the white noise in ARMA model, not interacting with the flow. not a
                        # subscale turublence problem..
                        state_future_mc_array = state_future_mc_array_noise_mou + self.noise_rec[i][:state_future_mc_array_noise_mou.shape[1]]

                        # transform normalized state: eta, to original state
                        state_future_mc_array = self.model.transform_eta_to_x(state_future_mc_array)

                        # state_list.append(state_future_mc_array)
                        state_for_current_time_list.append(state_future_mc_array)

                    state_list.append(state_for_current_time_list)

                # append for each time's the whole realization
                state_total_mc_list.append(np.array(state_list))

            # (800, 4, 10, 1, 2)
            QM_state_array = np.stack(state_total_mc_list, axis=1)

            # (800, 4, 10, 2)
            QM_state_array = np.squeeze(QM_state_array)

            QM_state_array = np.swapaxes(QM_state_array, 0, 1)
            QM_state_array = np.swapaxes(QM_state_array, 1, 2)

            QM_state_future_array = QM_state_array.reshape(-1, tspan.size, state.size)

            # QM_state_future_array = np.squeeze(np.stack(state_total_mc_list, axis=0), axis=2)


        elif self.LRAN_T > 1:

            # recurrent form
            # for each phi state, let's evolve the dynamics.


            for i in xrange(self.model.n_mc_samples):

                # stability test

                eigv,_ = np.linalg.eig(self.K[i].astype('float64'))
                if np.max(np.real(eigv)) > 0:
                    print('=====================')
                    print('unstable!')
                    print(self.K[i])
                    print(eigv)


                # for each sample
                print 'monte carlo run index = ', i, ': ', self.model.n_mc_samples

                state_list = [state]

                # loop over time
                for index_time in xrange(1, tspan.size):

                    # compute ``delta time``
                    delta_time = tspan[index_time] - tspan[0]

                    # linearly evolving phi to future ``delta time`` - for i-th realization
                    time_evolution_with_K = delta_time * self.K[i].astype('float64')

                    # convert to double precision, because sometimes single precision overfloat
                    time_evolution_with_K = time_evolution_with_K.astype('float64')

                    phi_state_at_t_mc_array = np.matmul(init_phi_state_mc_array[i].astype('float64'), expm(time_evolution_with_K)) # phi_0 -> phi_t

                    # reconstruct x from phi state at feature
                    state_future_mc_array = self.model.reconstruct_with_i_realization(phi=phi_state_at_t_mc_array, i=i) # phi_t -> eta_rec_t

                    # here we will introduce reconstriction error
                    # add reconstruction noise -> it is like the white noise in ARMA model, not interacting with the flow. not a
                    # subscale turublence problem..
                    state_future_mc_array = state_future_mc_array + self.noise_rec[i][:state_future_mc_array.shape[1]]

                    # transform normalized state: eta, to original state
                    state_future_mc_array = self.model.transform_eta_to_x(state_future_mc_array) # eta_rec_t -> x_rec_t

                    state_list.append(state_future_mc_array)

                # append for each time's the whole realization
                state_total_mc_list.append(state_list)

            # if self.mode == 'MAP':
            #     QM_state_future_array = np.stack(state_total_mc_list, axis=0)
            # else:
            QM_state_future_array = np.squeeze(np.stack(state_total_mc_list, axis=0), axis=2)

        else:

            raise NotImplementedError('not yet..')




        return QM_state_future_array

    def save_trj_comparison(self, true_tsnap,
                            true_trajectory,
                            additional_names=None):

        """Save the trajectory comparison as ``save_trj_comparison.npz``

        Args:
            true_tsnap (:obj:`numpy.ndarray`): the time array

            true_trajectory (:obj:`numpy.ndarray`): the ground true trajectory

            additional_names (:obj:`str`): name if additional name for trajectory comparison is necessary. Sometime there will be ``training`` and ``whole``.

        Returns:
            :obj:`list` : no longer use it, it is abandoned.

        """
        # compute prediction

        pred_trajectory_list = self.predict(tspan=true_tsnap, ic=true_trajectory[0:1, :])
        num_components = true_trajectory.shape[1]

        # TODO FOR BAYESIAN-LRAN (we will do D-DFORM and D-LRAN FORM later...)
        # todo: 1. run the code, see ADVIARD-LRAN works on cylinder.
        # todo: 2. test ADVInoARD-LRAN
        # todo: 3. test MAP-LRAN, which is equivalent to a reguarlized deterministic model..
        # todo: 4. besides, predict, and save_trj_comparison. other code function in ClassApoBayesEval should be examined..
        # todo: N.. then we go over the same thing for D-xxxx models, where Bayesian is not used at all.



        # SAVE
        # 1. true_trajectory.shape[1]

        if additional_names == None:
            file_name = 'save_trj_comparison.npz'
        else:
            file_name = 'save_trj_comparison_' + additional_names + '.npz'

        np.savez(self.save_dir + file_name,
                 num_components=true_trajectory.shape[1],
                 tt=true_tsnap,
                 ttrj=true_trajectory,
                 ptrj=pred_trajectory_list
                 )

        ## 3todo: write a multi-sample version of it...determine the shape of pred_trajectory
        # compute averaged MSE error in this time span
        mse_list = []
        # for i in xrange(num_components):
        #     error_square = np.square(pred_trajectory[:,i] - true_trajectory[:,i])
        #     mse = np.mean(error_square)
        #     mse_list.append(mse)

        return mse_list

    def computeTrueTrajectory(self, F, ic, tsnap):
        """ compute ground true trajectory for low dimensional problem, given initial condition and governing equation.

        We compute this trajectory by scipy.ode.integration using `dopri5`.

        Args:
            F (:obj:`function`): gonvering equation.

            ic (:obj:`numpy.ndarray`): initial condition.

            tsnap (:obj:`numpy.ndarray`): time array/.

        Returns:
            :obj:`numpy.ndarray` : true trajectory.

        """
        r = ode(F).set_integrator('dopri5')
        ic_list = ic.tolist()[0]
        r.set_initial_value(ic_list, tsnap[0])

        list_trueTraj = []
        list_trueTraj.append(r.y)
        for index_time in xrange(tsnap.size - 1):
            # print 'index =', index_time, tsnap[index_time + 1] - tsnap[index_time]
            y_current = r.integrate(r.t + tsnap[index_time + 1] - tsnap[index_time])
            list_trueTraj.append(y_current)

        return np.vstack(list_trueTraj)


class ClassApoEval(object):
    """Class for a posteriori evaluation with just deterministic Koopman Deep Learning.

    Args:
        model (:obj:`class`): the model class from ``lib.libm_model_interface`` .

            Note:

                model must have these methods & property
                    * model.computePhi
                    * model.linearEvolving
                    * model.reconstruct

        model_name (:obj:`str`): the name of the folder where the model is saved.

        case_name (:obj:`str`): the name of the problem case.

    Attributes:




    """
    def __init__(self, model, model_name, case_name):
        self.model = model
        self.model_name = model_name
        self.case_name = case_name

        self.save_dir = '../eval/' + case_name + '/' + model_name + '/'
        mkdir(self.save_dir)


    def predict(self, tspan, ic):
        """predicting the future state of dynamical system

        Args:
            tspan (:obj:`numpy.ndarray`): time array for prediction

            ic (:obj:`numpy.ndarray`): initial condition of the state

        Returns:

            :obj:`numpy.ndarray` : array of state in the future

        """
        state = ic
        state_list = [state]


        # direct evaluate time that is far away, not using recursive for each delta t

        phi_state = self.model.computePhi(state)

        print('initial phi_state = ', phi_state)

        for index_time in xrange(1, tspan.size):
            delta_time = tspan[index_time] - tspan[0]

            # linearly evolving phi to future
            # convert to double precision
            time_evolution_with_K = delta_time * self.model.get_linearEvolving()
            time_evolution_with_K = time_evolution_with_K.astype('float64')

            phi_state_at_t = np.matmul(phi_state,
                                       expm(time_evolution_with_K))

            # reconstruct x from phi state at feature
            state_future = self.model.reconstruct(phi_state_at_t)
            state_list.append(state_future)

        # return np.stack(state_list, axis=1)
        return np.vstack(state_list)


    def compute_eigen_trj(self, trj):
        """compute the trajectory of eigen-observables

        Simply projecting the trajectory onto the eigen-observables

        Args:
            trj (:obj:`numpy.ndarray`): true trajectory.

        Returns:
            :obj:`numpy.ndarray` : eigen-phi of that trajectory.

        """
        # obtain the eigenfunctions values along the trajectory
        return self.model.computeEigenPhi(trj[:, :])


    def save_trj_comparison(self, true_tsnap, true_trajectory, additional_names=None):
        """compare model result against true trajectory, plot and save

        Args:
            true_tsnap (:obj:`numpy.ndarray`): the time array

            true_trajectory (:obj:`numpy.ndarray`): the ground true trajectory

            additional_names (:obj:)

        Returns:
            :obj:`list` : MSE between true and predicted trajectory.

        """
        # compute prediction
        pred_trajectory = self.predict(tspan=true_tsnap, ic=true_trajectory[0:1, :])

        ## REMOVED
        # # plot
        num_components = true_trajectory.shape[1]
        # for i_comp in xrange(num_components):
        #     plt.figure()
        #     plt.plot(true_tsnap, true_trajectory[:, i_comp], 'k-', label='true')
        #     plt.plot(true_tsnap, pred_trajectory[:, i_comp], 'r--',label='pred')
        #     plt.xlabel('time')
        #     plt.ylabel(r'$x_' + str(i_comp + 1) + '$')
        #     lgd = plt.legend(bbox_to_anchor=(1, 0.5))
        #     plt.savefig(self.save_dir + self.model_name + '_' + self.case_name + '_' + \
        #                 'component_' + str(i_comp + 1) + '.png',  bbox_extra_artists=(lgd,),
        #                 bbox_inches='tight')

        ## SAVE
        # 1. true_trajectory.shape[1]
        if additional_names == None:
            file_name = 'save_trj_comparison.npz'
        else:
            file_name = 'save_trj_comparison_' + additional_names + '.npz'
        np.savez(self.save_dir + file_name,
                 num_components=true_trajectory.shape[1],
                 tt=true_tsnap,
                 ttrj=true_trajectory,
                 ptrj=pred_trajectory
                 )

        ## 3todo: write a multi-sample version of it...determine the shape of pred_trajectory
        # compute averaged MSE error in this time span
        mse_list = []
        for i in xrange(num_components):
            error_square = np.square(pred_trajectory[:,i] - true_trajectory[:,i])
            mse = np.mean(error_square)
            mse_list.append(mse)

        return mse_list

    def computeTrueTrajectory(self, F, ic, tsnap):
        """ compute ground true trajectory for low dimensional problem, given initial condition and governing equation.

        We compute this trajectory by scipy.ode.integration using `dopri5`.

        Args:
            F (:obj:`function`): gonvering equation.

            ic (:obj:`numpy.ndarray`): initial condition.

            tsnap (:obj:`numpy.ndarray`): time array/.

        Returns:
            :obj:`numpy.ndarray` : true trajectory.

        """
        r = ode(F).set_integrator('dopri5')
        ic_list = ic.tolist()[0]
        r.set_initial_value(ic_list, tsnap[0])

        list_trueTraj = []
        list_trueTraj.append(r.y)
        for index_time in xrange(tsnap.size - 1):
            # print 'index =', index_time, tsnap[index_time + 1] - tsnap[index_time]
            y_current = r.integrate(r.t + tsnap[index_time + 1] - tsnap[index_time])
            list_trueTraj.append(y_current)
        return np.vstack(list_trueTraj)
